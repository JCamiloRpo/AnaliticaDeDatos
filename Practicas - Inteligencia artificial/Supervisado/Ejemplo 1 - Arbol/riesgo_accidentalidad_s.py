# -*- coding: utf-8 -*-
"""Riesgo Accidentalidad - S.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SvEm5Du3qi6sISweWEF7EtfpVNtlyLFG

# Aprendizaje Supervisado -   Arboles de Decisión para la Predicción de Riesgo de Accidentalidad

1. Preparación de Datos
2. División de los datos
3. Aprendizaje del Modelo
4. Evaluación del Modelo
5. Predicción de Datos Futuros
"""

#Cargamos librerías principales
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""# 1. Preparación de Datos
-  Cargamos los datos
-  Conocemos los datos con estadísticos
- Transformación de datos  (sklearn sólo analiza variables numéricas)
"""

#Cargamos los datos
data = pd.read_csv("carRisk.csv", sep = ",", na_values = "unknown") #Cargar al dataframe
# pd.read_csv("NombreArchivo" , sep = "CaracterDeSeparacion", na_values = "DatosNulos")
data.head() #Mostrar los primeros registros

#Conocemos los datos
data.info() #Informacion sobre cada columna, tipo y numero de registros

#Corrección del tipo de datos
data['cartype']=data['cartype'].astype('category') #Se corrige el tipo de dato object a category dataframe['Columna']
data['risk']=data['risk'].astype('category') # .astype cambiar tipo de dato
data.info()

#Descripción de variables numéricas
print(data.describe()); # Estadistica descriptiva de las variables numericas
data.plot.hist(bins=5); # Grafica con .plot Histograma con .hist Numero de columnas con bins = #

#Descripción variables categóricas
data['cartype'].value_counts().plot(kind='bar') # Conteo de registros con .value_counts() y graficar .plot de tipo barra (kind='bar')

data['risk'].value_counts().plot(kind='bar')

#Sklearn sólo analiza variables numéricas entonces se pasan las variables tipo category a numeros
dummiesCarType = pd.get_dummies(data['cartype']) # Se crean una columna por categoria
# se pone un 1 en el registro que tiene esa categoria y 0 en los otros
data = data.drop('cartype', axis=1) #Eliminamos la columna original con .drop y con axis=1 se dice que es una columna, con 0 es un registro
data = data.join(dummiesCarType) #Adicionamos las dummies con .join
data.head()

#Se codifican las categorias de la variable objetivo
data["risk"]=data["risk"].replace({"high": 1, "low": 0}) #Con 2 categoria se puede hacer la conversión directa por numero
# .replace se remplazan las categorias de la columna
data.head()

"""# 2. División 70-30"""

#División 70-30
from sklearn.model_selection import train_test_split #Metodo para poder realizar la division
# Se deben mandar las variables por separado
X = data.drop("risk", axis = 1) # Quedan todas las Variables predictoras
Y = data['risk'] # Solo queda la Variable objetivo
# train_test_split(VPredictorias, VObejito, test_size=#Tamaño, stratify=VObjetivo [Para igual numero de 0 y 1]) - devuelve todos los conjutos
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)
Y_train.value_counts()

"""# 3. Aprendizaje del Modelo: A) Arbol de decisión"""

#Creación del modelo con el conjunto de entrenamiento
from sklearn import tree # Metodos para crear los arboles de decision
#(MinimoRegistroPorHoja[mas cantidad menor arbol], MaximoDeNiveles[menos cantidad mas arbol])
model = tree.DecisionTreeClassifier(min_samples_leaf=2, max_depth=10)
model.fit(X_train, Y_train) #Enviar conjuntos de aprendizaje

#Graficar el árbol
# Todos los import para configurar el ambiente de grafica
from sklearn.externals.six import StringIO  
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
dot_data = StringIO()
var_predictoras = X.columns.values
nom_clases= ['Low','High']# Nombres de los target in orden numérico ascendente.
export_graphviz(model, feature_names=var_predictoras, class_names= nom_clases, out_file=dot_data,filled=True, rounded=True,special_characters=True)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

"""# B) KNN"""

#Creación del modelo con el conjunto de entrenamiento
from sklearn import neighbors 
model = neighbors.KNeighborsClassifier(n_neighbors=3, metric='euclidean') #(n_neighbors=#DeVecinos, metric='TipoDeDistancia')
model.fit(X_train, Y_train)

"""# 4. Evaluación del modelo sobre el conjunto de prueba
- Exactitud
"""

#Evaluación sobre el conjunto de prueba
from sklearn import metrics

Y_pred = model.predict(X_test) # Probar el modelo en el conjunto de prueba (X_test), el resultado da la columna que se predijo

acc=metrics.accuracy_score(Y_test, Y_pred) #Comparar las columnas para ver la exactitud
print(f'Exactitud: {acc}') # Imprimir la exactitud

"""# 5. Predicción para datos futuros

- Cargamos los datos futuros
- Aplicamos el modelo para la predicción
"""

#Cargamos los datos futuros
data_fut = pd.read_csv("carRisk-future.csv", sep = ",", na_values = "unknown")
data_fut.head()

#Hacemos la predicción
Y_fut = model.predict(data_fut)
print(Y_fut)