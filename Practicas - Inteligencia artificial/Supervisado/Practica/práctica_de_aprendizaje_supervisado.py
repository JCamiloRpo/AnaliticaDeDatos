# -*- coding: utf-8 -*-
"""PRÁCTICA DE APRENDIZAJE SUPERVISADO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vsN8-5L9ywMWYMTFDTZT3j3lKxppSXxb

# Juan Camilo Restrepo Velez 000373886
# Wilder Valencia Ocampo 000375627

# Aprendizaje Supervisado

1. Preparación de Datos
2. División de los datos
3. Aprendizaje del Modelo
4. Evaluación del Modelo
5. Predicción de Datos Futuros
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""# 1. Preparación de Datos
-  Cargamos los datos
-  Conocemos los datos con estadísticos
- Seleccion de variables
- Limpieza de atipicos
- Limpieza de nulos
- Transformación de datos  (sklearn sólo analiza variables numéricas)
"""

data = pd.read_excel("Drug.xlsx", sheet_name=0)
data.info()

#Corrección del tipo de datos
data['SEXO']=data['SEXO'].astype('category')
data['PRESIÓN SANGUÍNEA']=data['PRESIÓN SANGUÍNEA'].astype('category')
data['COLESTEROL']= data['COLESTEROL'].astype('category')
data['MEDICAMENTO']= data['MEDICAMENTO'].astype('category')
data.info()

#Descripción de variables numéricas
print(data.describe())
data.plot.hist(bins=5)

#Descripción variables categóricas
data['SEXO'].value_counts().plot(kind='bar')#.valuer_Counts() conteo de registros .plot(kind='bar') grafico de barras

#Descripción variables categóricas
data['PRESIÓN SANGUÍNEA'].value_counts().plot(kind='bar')#.valuer_Counts() conteo de registros .plot(kind='bar') grafico de barras

#Descripción variables categóricas
data['COLESTEROL'].value_counts().plot(kind='bar')#.valuer_Counts() conteo de registros .plot(kind='bar') grafico de barras

#Descripción variables categóricas
data['MEDICAMENTO'].value_counts().plot(kind='bar')#.valuer_Counts() conteo de registros .plot(kind='bar') grafico de barras

#Selecion de variables
data=data.drop('ID',axis=1)
data.info()

#Limpiar atipicos
data.EDAD[data['EDAD']>100]=None
data.SODIO[data['SODIO']<0]=None
data.info()

#Limpieza de nulos: imputacion por la media
data['EDAD']=data['EDAD'].fillna(value=data['EDAD'].mean())
data['SODIO']=data['SODIO'].fillna(value=data['SODIO'].mean())
data.info()

#Sklearn sólo analiza variables numéricas
dummies = pd.get_dummies(data['PRESIÓN SANGUÍNEA'])
data = data.drop('PRESIÓN SANGUÍNEA', axis=1)
data = data.join(dummies)
data.head()

#Se codifican las categorias de la variable objetivo
data['SEXO']=data['SEXO'].replace({"F": 0, "M": 1})
data['COLESTEROL']=data['COLESTEROL'].replace({"NORMAL": 0, "HIGH": 1})
data['MEDICAMENTO']=data['MEDICAMENTO'].replace({"drugX": 0, "drugY": 1})
data.head()

"""# 2. División 70-30"""

#División 70-30
from sklearn.model_selection import train_test_split
X = data.drop("MEDICAMENTO", axis = 1) 
Y = data['MEDICAMENTO']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)
Y_train.value_counts()

"""# 3. Aprendizaje del Modelo

# A) Arbol de desicion
"""

#Creación del modelo con el conjunto de entrenamiento
from sklearn import tree
modelA = tree.DecisionTreeClassifier(min_samples_leaf=2, max_depth=10)
modelA.fit(X_train, Y_train)


from sklearn.externals.six import StringIO 
from IPython.display import Image 
from sklearn.tree import export_graphviz
import pydotplus
dot_data = StringIO()
var_predictoras = X.columns.values
nom_clases= ['drugX','drugY']
export_graphviz(modelA, feature_names=var_predictoras, class_names= nom_clases, out_file=dot_data,filled=True, rounded=True,special_characters=True)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

"""# B) Knn"""

#Creación del modelo con el conjunto de entrenamiento
from sklearn import neighbors
modelB = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')
modelB.fit(X_train,Y_train)

"""# 4. Evaluación del modelo sobre el conjunto de prueba
- Exactitud

# A) Arbol de desicion
"""

#Evaluación sobre el conjunto de prueba
from sklearn import metrics
Y_pred = modelA.predict(X_test)
acc=metrics.accuracy_score(Y_test, Y_pred)
print(f'Exactitud: {acc}')

"""# B) Knn"""

#Evaluación sobre el conjunto de prueba
from sklearn import metrics
Y_pred = modelB.predict(X_test)
acc=metrics.accuracy_score(Y_test, Y_pred)
print(f'Exactitud: {acc}')

"""# 5. Predicción para datos futuros

- Cargamos los datos futuros
- Aplicamos el modelo para la predicción
"""

#Cargamos los datos futuros
data_fut = pd.read_excel("Drug.xlsx", sheet_name=1)

data_fut = data_fut.drop('ID',axis=1) #Eliminar ID
dummies = pd.get_dummies(data_fut['PRESIÓN SANGUÍNEA'])
data_fut = data_fut.drop('PRESIÓN SANGUÍNEA', axis=1)
data_fut = data_fut.join(dummies)
data_fut['SEXO']=data_fut['SEXO'].replace({"F": 0, "M": 1})
data_fut['COLESTEROL']=data_fut['COLESTEROL'].replace({"NORMAL": 0, "HIGH": 1})
data_fut.head()

"""# A) Arbol de desicion"""

#Hacemos la predicción
Y_fut = modelA.predict(data_fut)
print(Y_fut)

"""# B) KNN"""

#Hacemos la predicción
Y_fut = modelB.predict(data_fut)
print(Y_fut)

"""# Conclusiones
- Se evidencia que por medio del metodo de arboles de desiciones se observan una mayor presicion en la evaluacióm de la exactitud respecto al metodo KNN, además.
- La predicción de ambos modelos arojan resultados diferentes debido a las tecnicas que estos internamente utilizada para la tomar una decision respecto al registro, esto se debe a que el arbol clasifica las variables por importancia y KNN, toma en cuenta a los registros mas cercanos.
- Personalmente consideramos más eficaz el metodo de arbol de desicion para la predicción de datos respecto al metodo KNN.
"""